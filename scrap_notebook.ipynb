{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_drep = \"../drep_genomes/OUTPUT/rep_genomes/\"\n",
    "drep_samples = {}\n",
    "for directory in os.listdir(path_drep):\n",
    "    path_2 = path_drep + directory\n",
    "    if os.path.isdir(path_2):\n",
    "        for directory_2 in os.listdir(path_2):\n",
    "            path_3 = path_2 + \"/\" + directory_2\n",
    "            if os.path.isdir(path_3):\n",
    "                for directory_3 in os.listdir(path_3):\n",
    "                    path_4 = path_3 + \"/\" + directory_3 + \"/\"\n",
    "                    if os.path.isdir(path_4):\n",
    "                        for directory_samp in os.listdir(path_4):\n",
    "                            samp_dir = path_4 + directory_samp\n",
    "                            if os.path.isdir(samp_dir):\n",
    "                                drep_samples[directory_samp] = path_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mmseqs_input(file_paths_list, outfile_path):\n",
    "    num_samples = len(file_paths_list)\n",
    "    final_cycle_ind = num_samples //1000\n",
    "    cat_cmd_1 = \"cat \"\n",
    "    for i in range(1000):\n",
    "        cat_cmd_1 += file_paths_list[i] + \" \"\n",
    "    cat_cmd_1 += \" > \" + outfile_path\n",
    "    os.system(cat_cmd_1)\n",
    "\n",
    "    for i in range(1, final_cycle_ind):\n",
    "        cat_cmd = \"cat \"\n",
    "        for j in range(i * 1000, (i + 1) * 1000):\n",
    "\n",
    "            cat_cmd += file_paths_list[j] + \" \"\n",
    "        cat_cmd += \" >> \" + outfile_path\n",
    "        os.system(cat_cmd)\n",
    "\n",
    "    cat_cmd = \"cat \"\n",
    "    for i in range(final_cycle_ind * 1000, num_samples):\n",
    "        cat_cmd += file_paths_list[i] + \" \"\n",
    "    cat_cmd += \" >> \" + outfile_path\n",
    "    os.system(cat_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make multi prodigal .faa inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodigal_paths = []\n",
    "for sample in drep_samples.keys():\n",
    "    sample_path = drep_samples[sample] + sample\n",
    "    prodigal_path = sample_path + \"/\" + sample + \".prodigal.faa.gz\"\n",
    "    prodigal_paths.append(prodigal_path)\n",
    "    \n",
    "outfile_path = \"../clusters/INPUT/mmseqs2_testdb_input.faa.gz\"\n",
    "\n",
    "#get_mmseqs_input(prodigal_paths, outfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_cmd = \"gsutil cp \" + outfile_path + \" gs://jluo_bucket/ggdb/clusters\"\n",
    "#os.system(backup_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make multi .gff inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"making multi .gff inputs\")\n",
    "gff_paths = []\n",
    "for sample in drep_samples.keys():\n",
    "    sample_path = drep_samples[sample] + sample\n",
    "    prodigal_path = sample_path + \"/\" + sample + \".prodigal.gff.gz\"\n",
    "    prodigal_paths.append(prodigal_path)\n",
    "    \n",
    "outfile_path_gff = \"../clusters/mmseqs2_testdb_input.gff.gz\"\n",
    "\n",
    "get_mmseqs_input(prodigal_paths, outfile_path_gff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_cmd_2 = \"gsutil cp \" + outfile_path_gff + \" gs://jluo_bucket/ggdb/clusters\"\n",
    "#os.system(backup_cmd_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data exploration of failed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_temp = \"ggdb_multisql_errorlog.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.read_csv(path_temp, header=None)\n",
    "in_df = in_df.iloc[3928:].set_index(0)\n",
    "#in_df.to_csv(path_temp, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose representatives for stringent clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through unique pid (cluster representatives) in tsv\n",
    "# explore data (distribution of cluster sizes, do any representatives have >1 *)\n",
    "# search for protein in fasta file (load in memory for now)\n",
    "# length + # of *'s\n",
    "# priority is (1) no * (2) length \n",
    "\n",
    "# 1. make pid to aa sequence dictionary\n",
    "# to do - this needs to be more scalable; can't load everything into memory\n",
    "pid_to_sequence_dict = {}\n",
    "path_coords = \"../clusters/proteines_testdb_10k.faa\"\n",
    "\n",
    "\n",
    "fasta_sequences = SeqIO.parse(open(path_coords),'fasta')\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    pid_to_sequence_dict[name] = sequence\n",
    "\n",
    "# 2. make pid to fragment dictionary\n",
    "#pid_to_frag\n",
    "\n",
    "def get_protein_info(pid):\n",
    "    p_complete = pid_to_sequence_dict[pid].count(\"*\") > 1\n",
    "    p_len = len(pid_to_sequence_dict[pid])\n",
    "    # get pid gff info - fragment?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tsv = \"../clusters/OUTPUT/stringent/tmp/clu_cluster_10k.tsv\"\n",
    "with open(path_tsv, \"r\") as in_file:\n",
    "    for line in csv.reader(in_file, delimiter='\\t'):\n",
    "        # search for protein\n",
    "        # get stats\n",
    "        # write to new file\n",
    "        unique_pid = line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster_df data ex to get cluster summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.read_csv(path_tsv, sep = '\\t', header = None)\n",
    "rep_counts = cluster_df.groupby(0).count()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pids_s = cluster_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ggdb",
   "name": "common-cpu.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m82"
  },
  "kernelspec": {
   "display_name": "ggdb",
   "language": "python",
   "name": "ggdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
